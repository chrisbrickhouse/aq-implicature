---
title             : "The effect of linking assumptions and number of response options on inferred scalar implicature rate"
shorttitle        : "Linking assumptions and implicature rate"
author: 
    
  - name          : "Masoud Jasbi"
    affiliation   : "1"
    corresponding : yes    # Define only one corresponding author
    address       : "Postal address"
    email         : "my@email.com"
  - name          : "Brandon Waldon"
    affiliation   : "1"
  - name          : "Judith Degen"
    affiliation   : "1"
affiliation:
  - id            : "1"
    institution   : "Stanford University"
author_note: |
  Add complete departmental affiliations for each author here. Each new line herein must be indented, like this line.
  Enter author note here.
abstract: |
  Enter abstract here. Each new line herein must be indented, like this line.
  
keywords          : "scalar implicature; methodology; linking assumption; experimental pragmatics; truth-value judgment task"
wordcount         : "X"
bibliography      : ["r-references.bib"]
figsintext        : yes
figurelist        : no
tablelist         : no
footnotelist      : no
lineno            : yes
mask              : no
class             : "man"
output            : papaja::apa6_pdf
editor_options: 
  chunk_output_type: console
---

```{r load_packages, include = FALSE}
library(grid)
library(gtable)
library(papaja)
library(tidyverse)
library(magrittr)
library(readr)
library(png)
library(jpeg)
library(lme4)
library(ggthemes)
library(forcats)
# library(brms)
theme_set(theme_bw(18))
```

```{r analysis_preferences}
# Seed for random number generation
set.seed(42)
```

# Introduction

The past 15 years have seen the rise and development of a bustling and exciting new field at the intersection of linguistics, psychology, and philosophy: *experimental pragmatics* [@bott2004;@Breheny2006;@DegenTanenhaus2015;@Grodner2010;@huang2009;@Geurts2009;@noveck2008] **XXX ADD MORE**. Experimental pragmatics is devoted to experimentally testing theories of how language is used in context. How do listeners draw inferences about the -- often underspecified -- linguistic signal they receive from speakers? How do speakers choose between the many utterance alternatives they have at their disposal?

The most prominently studied phenomenon in experimental pragmatics is undoubtedly *scalar implicature*. Scalar implicatures arise in virtue of a speaker producing the weaker of two ordered scalemates [@grice1975; hornXXX; @hirschberg1985; @Geurts2010]. Examples are provided in (1) and (2). 

1. 
  a. *Utterance:* Some of her pets are cats.
  b. *Implicature:* Some, but not all, of her pets are cats.
  c. *Scale:* <all, some>

2. 
  a. *Utterance:* She owns a cat or a dog.
  b. *Implicature:* She owns a cat or a dog, but not both.
  c. *Scale:* <and, or>  
  
A listener, upon observing the utterances in (1a) and (2a), typically infers that the speaker intended to convey the meanings in (1b) and (2b), respectively. Since @grice1975, the agreed-upon abstract rationalization the listener could give for their inference goes something like this: if the speaker knows whether the stronger alternative (e.g., *All of her pets are cats.*) is true, then if it is, they should have produced it. They chose not to. I believe the speaker knows whether the stronger alternative is true. Hence, it must not be true.

CONTINUE HERE: motivation for examining implicature rate assumptions:

* surging interest in differences in implicature rates (eg van tiel, dgen tanenhaus)
* implicature rates serve as basis for claims about online processing (bott & noveck, degen tanenhaus)
* implicature rates serve as basis for claims about children (bishop katsos, barner, frank)

* add @deneys2007
* @demarneffetonhauser for investigations of scalar adjectives, and @vantiel


```{r linkvisualization, fig.env = "figure", fig.align='center', fig.width=5, set.cap.width=T, num.cols.cap=1,fig.cap = "Strong and weak link from response options to researcher inference about scalar implicature rate, exemplified for the disjunctive utterance when the conjunction is true."}
link_img <- png::readPNG("writeup_files/figures/link-visualization.png")
grid::grid.raster(link_img)
```


* In a truth-value judgment task, how do we know whether an interpretation is literal or the result of an implicature computation?

Explain the setup
* the speaker produces weaker alternative from the scale
* the facts are such that the stronger alternative is true  

Traditional Linking Hypotheses:
* If an implicature is calculated, the participant chooses a Non-True/Non-Right response
* If an implicature is calculated, the participant chooses the Wrong/False response
* If an implicature is calculated, the participant chooses the lower end of the scale (2: wrong/False, 3: wrong, 4: wrong/kinda-wrong, 5: wrong/kinda-wrong)

Questions:
* Do these linking hypotheses give us different measures of implicature computation?
* If they do differ, which one is most stable?

Alternative Linking Hypothesis:
* RSA: Response behavior across conditions (utterance-card combinations) and dependent measures can be predicted by a linking hypothesis that assumes that participants are behaving like soft-optimal RSA speakers and provide a particular response (eg TRUE) to an utterance u if the RSA speaker probability of u (given the card) is within a particular probability interval (eg, within the interval [theta, 1]).

* Differences between traditional approaches and RSA: 1. The traditional linking hypotheses are based on a binary implicature/literal theory of pragmatic reasoning but RSA gives a continuous measure of pragmatic reasoning and allows for better predicting response behavior with multiple options.

# Background

* discussing the ways people in tha past have measured the "implicature rate".
* it seems like the literature takes the n(not-True)/n(Total) as the proporition of responses caused by implicature calculation
* BUT, I remember that Jesse Snedeker said it's NOT n(not-True)/n(Total) but it is n(False)/n(Total)
* However, this is probably not a consensus in the field because Katsos & Bishop consider the mid-point response "big" on the scale small-big-huge (strawberry) to be the result of implicture caculation

* what is the most common measure of "implicature rate" in the literature?
Binary True/False: Noveck 2001, Chemla & Spector 2011, 
Ternary: Katsos & Bishop 2011

# Methods

```{r importData, warning=FALSE, echo=FALSE}
data <- read_csv("experiments/main/3_processed_data/data_main.csv")

data$response_type <- recode(data$response_type, quatenary = "quaternary", tertiary = "ternary")

# define an implicature column for the ad-hoc and implicature trials
pragmatic_trials <- 
  data %>%
  filter(trial_type == "XY_XorY" | trial_type=="XY_X")

# adding a column that defines pragmatic vs. literal

# high definition only considers the highest point on the scale as "literal"
pragmatic_trials$high<-1
pragmatic_trials[pragmatic_trials$response=="Right",]$high <-0

# low definition only considers the lowers point on the scale as implicature 
pragmatic_trials$low<-0
pragmatic_trials[pragmatic_trials$response=="Wrong",]$low <-1

implicature_rate <- 
  pragmatic_trials %>% gather("definition","implicature", high:low)

# changing trial type names to exhaustive vs. scalar
implicature_rate$trial_type <-fct_recode(pragmatic_trials$trial_type, 
                                         exhaustive = "XY_X", scalar = "XY_XorY")
```

## Participants

```{r participants}
participants_info <-
  data %>%
  group_by(response_type) %>%
  summarise(count = n()/24)
```

200 participants were recruited using Amazon Mechanical Turk (binary=`r participants_info$count[1]`, ternary`r participants_info$count[4]`, quaternary=`r participants_info$count[2]`, quinary=`r participants_info$count[3]`). No participant was excluded from the final analysis.

## Procedure

The study was administered online and through Amazon Mechanical Turk. Participants were introduced to a set of cards with pictures of one or two animals (Figure \@ref(fig:stimuli)). They were told that a blindfolded fictional character called Bob is going to guess what animals are on the card. In each trial, participants saw a card as well as a sentence representing Bob's guess. For example they saw a card with a cat on it and read the sentence "there is a cat on the card." The study ended after 24 trials. At the end participants were asked about their   
You can access and view [the online study here]().

## Design and Materials

```{r stimuli, fig.env = "figure", fig.pos = "t", fig.align='center', fig.width=3, fig.height=1.5, set.cap.width=T, num.cols.cap=1, fig.width=1.5,fig.cap = "Cards used in the connective guessing game."}
cards_img <- jpeg::readJPEG("experiments/figs/cards.jpg")
grid::grid.raster(cards_img)
```

The design had two main manipulaitons: the type of card and the type of guess. There were two types of cards. Cards with only one animal on them and cards with two animals. Animals were chosen from the following set: cat, dog, and elephant  There were three types of guesses: simple (e.g. *There is a cat*), conjunctive (e.g. *There is a cat and a dog*), and disjunctive (e.g. *There is a cat or a dog*).

In each trial, the animal labels used in the guess and the animal images on the card may have no overlap (e.g. Image: dog, Guess: *There is a cat or an elephant*), a partial overlap (e.g. Image: Cat, Guess: *There is a cat or an elephant*), or a total overlap (e.g. Image: cat and elephant, Guess: *There is a cat or an elephant*). Crossing the number of animals on the card, the type of guess, and the overlap between the guess and the card results in 12 different possible trial types. We chose 8 trial types (Figure \@ref(fig:trials)), balancing the number of one-animal vs. two-animal cards, simple vs. connective guesses, and expected true vs. false trials. 

The study used five different types of measurements. 1. two-options (true vs. false) 2. two-options (wrong vs. right) 3. three-options (wrong, neither, right) 4. four-options (wrong, kinda wrong, kinda right, right) 5. five-options (wrong, kinda wrong, neither, kinda right, right).

```{r trials, fig.env = "figure", fig.pos = "t", fig.align='center', fig.width=4, fig.height=2, set.cap.width=T, num.cols.cap=1, fig.width=1.5, fig.cap = "Trial types represented by example cards and guesses."}
trials_img <- jpeg::readJPEG("experiments/figs/trialTypes.jpg")
grid::grid.raster(trials_img)
```

## Pre-registered Analysis

<!--We used `r cite_r("r-references.bib")` for all our analyses.-->

We are primarily concerned with the "rate of implicatures" in an experimental study. Two trial types are predicted to include pragmatic implicatures. First, trials where there are two animals on the card but the fictional character guesses using the connective *or*; for example "cat or dog" when the card has both a cat and a dog on it. We call such trials "scalar" trials. Second, trials where there are two animals on the card but the character guesses only one; for example "cat" when the card has a cat and a dog on it. We call such trials "exhaustive". In our assessment of implicature rate we focus on these two types of trials.

We define "implicature rate" in two ways: 

This study set out to test two hypotheses. First, that the proportion of pragmatic vs. literal responses in a truth values judgement task changes based on the number of response options available to the participants. We test this hypothesis formally using a binomial mixed effects model with the fixed effect of response type and the random intercept for participants as well as random intercept and slope for 

A second hypothesis was that the definition of what responses count as participants computing an implicature may affect the estimated rate of implicature in the experimental task. 

# Results

```{r binaryPlot, fig.env = "figure", fig.pos = "t", fig.align='center', fig.width=8, fig.height=4, set.cap.width=T, num.cols.cap=1, fig.cap = "Adults' two-alternative forced choice judgments in the connective guessing game."}

binary_summary<-
  data %>%
  filter(response_type=="binary") %>%
  group_by(card_type, guess_type, response) %>%
  summarize(count=n()) %>%
  group_by(card_type, guess_type) %>%
  mutate(total = sum(count), proportion=count/total)

binary_summary$response <- factor(binary_summary$response, levels = c("Wrong","Right"))
binary_summary$guess_type <- factor(binary_summary$guess_type, levels = c("Z","X","XandY","XorY"))
binary_summary$guess_type <- recode(binary_summary$guess_type, Z = "elephant", X = "cat", XandY = "cat and dog", XorY ="cat or dog")

binary_plot<-
  binary_summary %>%
  ggplot(aes(x=response, y=proportion, fill=response)) +
  geom_bar(stat = "identity", position="dodge", width = 0.6) +
#  geom_linerange(aes(ymax=cih, ymin=cil), position= position_dodge(width=0.9)) + 
  facet_grid(card_type~guess_type) +
  labs(x="", y="")+
  theme_few() +
  theme(text = element_text(size=15)) +
  scale_fill_manual(values = c("red4", "springgreen3"), guide=FALSE)

cat <- 
  readJPEG("experiments/figs/cat_card.jpg") %>%
  rasterGrob(width=0.9)

cat_dog <- 
  readJPEG("experiments/figs/catdog_card.jpg")%>%
  rasterGrob(width=0.9)

binary_plot_g <- ggplot_gtable(ggplot_build(binary_plot))

strips <- grep("strip-r", binary_plot_g$layout$name)

new_grobs <- list(cat, cat_dog)

binary_plot_g <- with(binary_plot_g$layout[strips,],
          gtable_add_grob(binary_plot_g, new_grobs,
                          t=t, l=l, b=b, r=r, name="cards"))        
binary_plot_g$widths[[11]] <- unit(2.5,"cm")

grid.draw(binary_plot_g)
```

```{r ternaryPlot, fig.env = "figure", fig.pos = "t", fig.align='center', fig.width=8, fig.height=4, set.cap.width=T, num.cols.cap=1, fig.cap = "Adults' three-alternative forced choice judgments in the connective guessing game."}

ternary_summary<-
  data %>%
  filter(response_type=="ternary") %>%
  group_by(card_type, guess_type, response) %>%
  summarize(count=n()) %>%
  group_by(card_type, guess_type) %>%
  mutate(total = sum(count), proportion=count/total)

ternary_summary$response <- factor(ternary_summary$response, levels = c("Wrong","Neither", "Right"))
ternary_summary$guess_type <- factor(ternary_summary$guess_type, levels = c("Z","X","XandY","XorY"))
ternary_summary$guess_type <- recode(ternary_summary$guess_type, Z = "elephant", X = "cat", XandY = "cat and dog", XorY ="cat or dog")

ternary_plot<-
  ternary_summary %>%
  ggplot(aes(x=response, y=proportion, fill=response)) +
  geom_bar(stat = "identity", position="dodge", width = 0.6) +
#  geom_linerange(aes(ymax=cih, ymin=cil), position= position_dodge(width=0.9)) + 
  facet_grid(card_type~guess_type) +
  labs(x="", y="")+
  theme_few() +
  theme(text = element_text(size=15)) +
  scale_fill_manual(values = c("red4","grey", "springgreen3"), guide=FALSE)

cat <- 
  readJPEG("experiments/figs/cat_card.jpg") %>%
  rasterGrob(width=0.9)

cat_dog <- 
  readJPEG("experiments/figs/catdog_card.jpg")%>%
  rasterGrob(width=0.9)

ternary_plot_g <- ggplot_gtable(ggplot_build(ternary_plot))

strips <- grep("strip-r", ternary_plot_g$layout$name)

new_grobs <- list(cat, cat_dog)

ternary_plot_g <- with(ternary_plot_g$layout[strips,],
          gtable_add_grob(ternary_plot_g, new_grobs,
                          t=t, l=l, b=b, r=r, name="cards"))        
ternary_plot_g$widths[[11]] <- unit(2.5,"cm")

grid.draw(ternary_plot_g)
```

```{r quaternaryPlot, fig.env = "figure", fig.pos = "t", fig.align='center', fig.width=8, fig.height=4, set.cap.width=T, num.cols.cap=1, fig.cap = "Adults' three-alternative forced choice judgments in the connective guessing game."}

quaternary_summary<-
  data %>%
  filter(response_type=="quaternary") %>%
  group_by(card_type, guess_type, response) %>%
  summarize(count=n()) %>%
  group_by(card_type, guess_type) %>%
  mutate(total = sum(count), proportion=count/total)

quaternary_summary$response <- factor(quaternary_summary$response, levels = c("Wrong","Kinda Wrong", "Kinda Right", "Right"))
quaternary_summary$guess_type <- factor(quaternary_summary$guess_type, levels = c("Z","X","XandY","XorY"))
quaternary_summary$guess_type <- recode(quaternary_summary$guess_type, Z = "elephant", X = "cat", XandY = "cat and dog", XorY ="cat or dog")

quaternary_plot<-
  quaternary_summary %>%
  ggplot(aes(x=response, y=proportion, fill=response)) +
  geom_bar(stat = "identity", position="dodge", width = 0.6) +
#  geom_linerange(aes(ymax=cih, ymin=cil), position= position_dodge(width=0.9)) + 
  facet_grid(card_type~guess_type) +
  labs(x="", y="")+
  theme_few() +
  theme(text = element_text(size=17), axis.text.x = element_text(angle = 90, hjust = 1)) +
  scale_fill_manual(values = c("red4", "red3", "springgreen2", "springgreen3"), guide=FALSE)

cat <- 
  readJPEG("experiments/figs/cat_card.jpg") %>%
  rasterGrob(width=0.9)

cat_dog <- 
  readJPEG("experiments/figs/catdog_card.jpg")%>%
  rasterGrob(width=0.9)

quaternary_plot_g <- ggplot_gtable(ggplot_build(quaternary_plot))

strips <- grep("strip-r", quaternary_plot_g$layout$name)

new_grobs <- list(cat, cat_dog)

quaternary_plot_g <- with(quaternary_plot_g$layout[strips,],
          gtable_add_grob(quaternary_plot_g, new_grobs,
                          t=t, l=l, b=b, r=r, name="cards"))        
quaternary_plot_g$widths[[11]] <- unit(2.5,"cm")

grid.draw(quaternary_plot_g)
```

```{r quinaryPlot, fig.env = "figure", fig.pos = "t", fig.align='center', fig.width=8, fig.height=4, set.cap.width=T, num.cols.cap=1, fig.cap = "Adults' three-alternative forced choice judgments in the connective guessing game."}

quinary_summary<-
  data %>%
  filter(response_type=="quinary") %>%
  group_by(card_type, guess_type, response) %>%
  summarize(count=n()) %>%
  group_by(card_type, guess_type) %>%
  mutate(total = sum(count), proportion=count/total)

quinary_summary$response <- factor(quinary_summary$response, levels = c("Wrong","Kinda Wrong", "Neither", "Kinda Right", "Right"))
quinary_summary$guess_type <- factor(quinary_summary$guess_type, levels = c("Z","X","XandY","XorY"))
quinary_summary$guess_type <- recode(quinary_summary$guess_type, Z = "elephant", X = "cat", XandY = "cat and dog", XorY ="cat or dog")

quinary_plot<-
  quinary_summary %>%
  ggplot(aes(x=response, y=proportion, fill=response)) +
  geom_bar(stat = "identity", position="dodge", width = 0.6) +
#  geom_linerange(aes(ymax=cih, ymin=cil), position= position_dodge(width=0.9)) + 
  facet_grid(card_type~guess_type) +
  labs(x="", y="")+
  theme_few() +
  theme(text = element_text(size=17), axis.text.x = element_text(angle = 90, hjust = 1)) +
  scale_fill_manual(values = c("red4", "red3", "grey", "springgreen2", "springgreen3"), guide=FALSE)

cat <- 
  readJPEG("experiments/figs/cat_card.jpg") %>%
  rasterGrob(width=0.9)

cat_dog <- 
  readJPEG("experiments/figs/catdog_card.jpg")%>%
  rasterGrob(width=0.9)

quinary_plot_g <- ggplot_gtable(ggplot_build(quinary_plot))

strips <- grep("strip-r", quinary_plot_g$layout$name)

new_grobs <- list(cat, cat_dog)

quinary_plot_g <- with(quinary_plot_g$layout[strips,],
          gtable_add_grob(quinary_plot_g, new_grobs,
                          t=t, l=l, b=b, r=r, name="cards"))        
quinary_plot_g$widths[[11]] <- unit(2.5,"cm")

grid.draw(quinary_plot_g)
```


```{r}
results<-
  data %>%
  group_by(response_type, trial_type, response) %>%
  summarize(counts = n()) %>%
  group_by(trial_type, response_type) %>%
  mutate(total = sum(counts), proportion = counts/total)
```

```{r}
ggplot(results, aes(x=response,y=proportion)) +
  geom_bar(stat="identity") +
  facet_grid(response_type~trial_type, drop = TRUE) +
  theme_few()
```

* make sure to break down based on whether participants had logical training or not.


# Analysis

```{r implicatureResultss}
implicature_results<-
  implicature_rate %>%
  group_by(response_type, trial_type, implicature, definition) %>%
  summarize(counts = n()) %>%
  group_by(response_type, trial_type, definition) %>%
  mutate(total = sum(counts), proportion = counts/total)
```

```{r}
ggplot(implicature_results, aes(x=as.factor(implicature),y=proportion)) +
  geom_bar(stat="identity", position = "dodge") +
  facet_grid(response_type~definition + trial_type, drop = TRUE) +
  theme_few() + 
  labs(x="Implicature")
```


```{r}
implicature_rate$card <- implicature_rate$card %>% tolower()

implicature_analysis_a <- glmer(implicature ~ definition * response_type + trial_type + (1+response_type|card) + (1|participant), family="binomial", data=implicature_rate)

summary(implicature_analysis_a)

# implicature_analysis_b <- brm(implicature ~ definition * response_type + trial_type + (1+response_type|trial_type) + (1|participant), family="binomial", data=implicature_rate)
```



# Modeling

# Discussion


\newpage

# References
```{r create_r-references}
r_refs(file = "r-references.bib")
```

\setlength{\parindent}{-0.5in}
\setlength{\leftskip}{0.5in}
